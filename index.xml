<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>shank</title>
    <link>https://shankisme.com/</link>
    <description>Recent content on shank</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Tue, 28 Jun 2022 10:56:02 +0800</lastBuildDate><atom:link href="https://shankisme.com/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>CAN网络设备在k8s集群内的管理方式</title>
      <link>https://shankisme.com/posts/can%E8%AE%BE%E5%A4%87%E5%9C%A8k8s%E9%9B%86%E7%BE%A4%E5%86%85%E7%9A%84%E7%AE%A1%E7%90%86%E6%96%B9%E5%BC%8F/</link>
      <pubDate>Tue, 28 Jun 2022 10:56:02 +0800</pubDate>
      
      <guid>https://shankisme.com/posts/can%E8%AE%BE%E5%A4%87%E5%9C%A8k8s%E9%9B%86%E7%BE%A4%E5%86%85%E7%9A%84%E7%AE%A1%E7%90%86%E6%96%B9%E5%BC%8F/</guid>
      <description>背景 车上的CAN网络接口通常在host网络中创建，使用CAN接口的项目需要在host网络中运行，因此可能会产生网络栈资源使用冲突，导致项目启动失败，所以需要使用某种技术能让容器网络中的项目访问CAN网络设备。
已知开源方案 k8s-device-plugin-socketcan for docker k8s-socketcan for containerd 这两种方案基于k8s device plugin监听pod的期望资源并分配实际资源。
yaml例如：
apiVersion: v1 kind: Pod metadata: name: demo-pod spec: containers: - name: demo-container-1 image: k8s.gcr.io/pause:2.0 resources: limits: shankisme.com/can: 1 //max is 1 如果某pod配置了指定资源，就将CAN的netns设置成该pod的netns，两个项目间的区别仅仅在于容器运行时一个只支持docker,另一个只支持containerd。
问题 没有管理好CAN的生命周期，当CAN所在的netns被删除时，CAN也会被删除，需要CAN相关的驱动或守护进程兜底，重新创建出新的CAN接口。
CAN接口资源是唯一的，意味着使用CAN的项目只能有一个副本，deployment滚动更新时需要保证老pod稳定运行，不能移除CAN，又要保证新pod拿到CAN达到healthy状态才能完成滚动更新，直接导致死锁。
一般来说k8s device plugin适合分配像gpu、cpu、内存这类分配数可大于1的整数计算资源，而CAN网络接口pod内存在即可，和数量无关，所以基于k8s device plugin的方案不合适。
方案 平滑升级项目版本是有必要的，k8s deployment的滚动更新必然要求同时有多个CAN，单纯移动CAN的想法似乎应该被抛弃。
流量转发 学习docker网络原理的时候，我们会了解到一些特殊的网络设备：veth pair、bridge。
docker的默认网络模式bridge，使用docker0(bridge网络设备)作为host的ethX与其他netns的ethX流量转发中枢，使用veth为容器网络提供ethX接口与外界通信。
CAN网络设备也有类似的网桥cangw和连接两个netns的vxcan实现上面的流量转发方案, 不过区别是bridge根据ip转发，cangw是分发相同流量。
环境要求 linux should support can kernel module(sudo modprobe can to check and load)
linux should support vxcan kernel module(sudo modprobe vxcan to check and load)</description>
    </item>
    
    <item>
      <title>面向API server CRUD的探索</title>
      <link>https://shankisme.com/posts/clientset/</link>
      <pubDate>Mon, 13 Dec 2021 15:35:21 +0800</pubDate>
      
      <guid>https://shankisme.com/posts/clientset/</guid>
      <description>前言 某些场景下，我们可能不需要operator的那种运维能力，能对资源CRUD就够了，client-go中的client就是非常不错的选择。
前置知识 GVR、GVK 在整个kubernetes架构中，资源是最重要的概念，可以说k8s的生态系统都围绕资源运作，它本质上是一个资源控制系统：注册、管理、调度资源并维护资源状态。
k8s将资源分组和版本化，形成了:
Group: 资源组 Version: 资源版本 Resource: 资源 Kind: 资源种类, 与resource为同级概念 k8s系统支持多个Group，每个Group支持多个Version，每个Version支持多个Resource，其中部分资源会拥有子资源，如Deployment会拥有Status子资源。
资源组、资源版本、资源、子资源的完整表现形式为：&amp;lt;group&amp;gt;/&amp;lt;version&amp;gt;/&amp;lt;resource&amp;gt;/&amp;lt;subresource&amp;gt;
如Deployment资源，完整表现形式为：apps/v1/deployments/status
资源实例化后为一个资源对象，拥有资源组、资源版本、资源种类，表现形式为：&amp;lt;group&amp;gt;/&amp;lt;version&amp;gt;,Kind=&amp;lt;kind&amp;gt;
如Deployment, 完整表现形式为apps/v1,Kind=Deployment
client-go k8s使用client-go作为go语言官方编程式交互客户端库，提供对k8s API server的交互式访问。
client-go支持4种client对象与k8s交互，分别是ClientSet、DynamicClient、DiscoveryClient、RESTClient
RESTClient最基础，它封装了HTTPRequest,实现了RESTful风格的API，ClientSet、DynamicClinet以及DiscoveryClient都是基于RESTfulClient实现的。
RESTClient package main import ( &amp;#34;context&amp;#34; &amp;#34;fmt&amp;#34; corev1 &amp;#34;k8s.io/api/core/v1&amp;#34; metav1 &amp;#34;k8s.io/apimachinery/pkg/apis/meta/v1&amp;#34; &amp;#34;k8s.io/client-go/kubernetes/scheme&amp;#34; &amp;#34;k8s.io/client-go/rest&amp;#34; &amp;#34;k8s.io/client-go/tools/clientcmd&amp;#34; ) func main() { config, err := clientcmd.BuildConfigFromFlags(&amp;#34;&amp;#34;, &amp;#34;/etc/rancher/k3s/k3s.yaml&amp;#34;) if err != nil { panic(err) } config.APIPath = &amp;#34;api&amp;#34; // group core version v1 config.GroupVersion = &amp;amp;corev1.SchemeGroupVersion // set codec config.</description>
    </item>
    
    <item>
      <title>聊一聊kubernetes operator</title>
      <link>https://shankisme.com/posts/%E8%81%8A%E4%B8%80%E8%81%8Akubernetes-operator/</link>
      <pubDate>Tue, 07 Dec 2021 20:13:53 +0800</pubDate>
      
      <guid>https://shankisme.com/posts/%E8%81%8A%E4%B8%80%E8%81%8Akubernetes-operator/</guid>
      <description>前言 微服务兴起，许多业务被部署在了k8s上，大多数业务开发人员日常接触到的基本是build-in资源(ingress service deployment replicaset pod hpa)，因此会认为kubernetes(以下简称k8s)是一个设计优秀的paas平台，在k8s中创建资源的人员会被称为yaml工程师🤣。
这么说显得k8s很无聊, 资源只是对象状态的描述，实际执行动作的是k8s的组件(kubelet kube-proxy等)，可以说k8s的执行能力足够强大，能在存储、网络、容器上玩出花，你完全可以组织自己的资源格式(crd)，利用k8s的能力做自己想做的事，k8s本质上是带有强大执行力的分布式资源管理平台，这种动词-名词分离的解释应该能让你更好地理解k8s。
当今许多对扩展性可用性要求高的项目（TiDB等），更青睐于使用k8s作为基座，这样的深度结合只会让k8s越来越流行。
得益于强大的插件机制，k8s还能自定义资源(crd/cr)，自定义controller，自定义api server, 自定义admission webhook，他们让你能有效组合k8s的执行力，做一些有逻辑的事。当下最流行的莫过于玩crd+controller了。
为了让看官更好的了解operator（controller + crd + cr），咱们从k8s两大设计思想：声明式API、控制循环说起。
声明式API 声明式与之相对的是命令式, 命令式顾名思义，让目标按指定命令做事；而声明式则是提供目标一个期望状态，让目标朝期望状态去变更。
看得出来，命令式够简洁，但要花费巨大代价保证命令执行拥有原子性幂等性。
提供期望状态看似冗余，但只要期望状态能被执行者获取到，执行者就能不断尝试着去达成期望状态，过程简单。
而API嘛，指的是k8s apiserver提供的RESTful http接口，创建资源接口需要接收完整的资源期望状态定义, 期望状态指的就是spec中的描述，与之对应的实际状态由执行者（controller）记录在status中。
这也是为啥我们在用kubectl查看资源信息的时候后出现额外的status字段，这实际上是执行者帮我们记录的，专业点的叫法是规约(spec) - 状态(status)分离。比如pod, 除了元信息外，状态从spec和status字段开始展开。
type Pod struct { metav1.TypeMeta `json:&amp;#34;,inline&amp;#34;` metav1.ObjectMeta `json:&amp;#34;metadata,omitempty&amp;#34; protobuf:&amp;#34;bytes,1,opt,name=metadata&amp;#34;` Spec PodSpec `json:&amp;#34;spec,omitempty&amp;#34; protobuf:&amp;#34;bytes,2,opt,name=spec&amp;#34;` Status PodStatus `json:&amp;#34;status,omitempty&amp;#34; protobuf:&amp;#34;bytes,3,opt,name=status&amp;#34;` } 控制循环（control loop） 资源的理想状态存储在k8s的apiserver中，为了让资源由实际状态向期望状态靠拢, 执行者需要监听资源期望状态的增删改事件，这些事件会触发执行者以定时重复执行方式调用对应的handler处理事件, 直到满足期望状态为止，之后执行者再把操作结果记录到实际状态中。
执行者 我们知道，kubelet是k8s自带组件，主要功能通过监听pod期望状态变化事件并做一些事确保本地的pod处于期望状态。
kube-proxy同样也会处理pod的增删改事件，它不断地刷新本机linux网络设备的配置，来确保pod网络通畅。
还有我们常用的deployment、cronJob、statefulset等，它们拥有自己的controller做控制循环，这些controller 运行在组件controller-manager内。
然而不像上面提到的处理k8s原生资源的执行者，这次我们聊的operator,由crd(custom resource definition)、cr(custom resource)、controller组成。
crd用来描述你想创建的资源应该有哪些字段，cr是crd的具体化实现，与对象，对象实例之间区别类似。
我们自己实现的controller控制的目标就是cr, 它的实现原理等同controller-manager中的原生controller：
依靠informer的ListAndWatch方法将指定资源的状态缓存在内存中，并不断监控状态变化
reconcile方法中的业务逻辑会根据资源的期望状态，对外部世界作出改变，如果处理失败，就重新入队，按某种规则到某个时间继续进入reconcile, 直到处理完成。</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://shankisme.com/about/</link>
      <pubDate>Sat, 27 Nov 2021 01:11:42 +0800</pubDate>
      
      <guid>https://shankisme.com/about/</guid>
      <description>你好呀😄 ，我叫shank
苏州人，2021年本科毕业于华东师范大学，软件工程专业，gopher，对云原生感兴趣
目前在上海某互联网公司从事infra相关工作
如有任何问题欢迎通过发邮件或留言方式和我交流</description>
    </item>
    
    <item>
      <title>go-mock初探</title>
      <link>https://shankisme.com/posts/go-mock%E5%88%9D%E6%8E%A2/</link>
      <pubDate>Fri, 22 Jan 2021 01:41:04 +0800</pubDate>
      
      <guid>https://shankisme.com/posts/go-mock%E5%88%9D%E6%8E%A2/</guid>
      <description>go mock 用于虚拟接口。一般只要提供interface，无论有没有实现该interface的类型，gomock会根据接口的输入输出提供一个实现了该interface的mock实例，同时在自定义mock实例的输入输出前，可以根据期望过滤输入，产生想要的输出或调用某些函数。说的很晦涩，看点代码吧。
目录结构：
trymock/ /db |--db.go |--db_test.go /mock |--db_mock.go // generated by mockgen //db.go type DB interface { Get(key string) (int, error) } func GetFromDB(db DB, key string) int { if value, err := db.Get(key); err == nil { return value } return -1 } gomock中，DB实例只能通过传参传入生成mock文件
mockgen -source=db.go -destination=db_mock.go -package=mock gomock生成的db_mock.go如下
//db_mock.go // Code generated by MockGen. DO NOT EDIT. // Source: db.go // Package mock_db is a generated GoMock package.</description>
    </item>
    
    <item>
      <title>汽车CAN总线复习笔记</title>
      <link>https://shankisme.com/posts/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E6%B1%BD%E8%BD%A6can%E6%80%BB%E7%BA%BF%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Sat, 16 Jan 2021 20:45:02 +0800</pubDate>
      
      <guid>https://shankisme.com/posts/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E6%B1%BD%E8%BD%A6can%E6%80%BB%E7%BA%BF%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>CAN总线使用总线技术，取代了传统的点对点布线方式连接汽车电子控制单元（ECU）, 解决了传统布线方式中线束多，布线难，成本高等问题。
figure-normal (without any classes)
CAN总线标准 CAN总线标准规定了物理层和数据链路层（参考计算机网络OSI七层网络模型），应用层需要用户自定义，不同的CAN标准中，对物理层的要求不同，对数据链路层的要求是相同的。
CAN网络物理层 连接在CAN总线上的设备叫做节点设备（CAN Node），CAN网络的拓扑一般为线型。线束最常用的是双绞线，线上传输为对称的差分电平信号。</description>
    </item>
    
    <item>
      <title>kong网关consumer service route plugin 理解与实践</title>
      <link>https://shankisme.com/posts/kong%E7%BD%91%E5%85%B3consumer-service-route-plugin-%E7%90%86%E8%A7%A3%E4%B8%8E%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Sun, 22 Nov 2020 13:40:56 +0800</pubDate>
      
      <guid>https://shankisme.com/posts/kong%E7%BD%91%E5%85%B3consumer-service-route-plugin-%E7%90%86%E8%A7%A3%E4%B8%8E%E5%AE%9E%E8%B7%B5/</guid>
      <description>近几天在学习api网关kong，发现中文网基本没人发表关于kong的consumer、plugin、route、service的进一步探索和使用相关文章，只是分开描述了单独的概念和做简单配置，因此为了补全这个缺失，我尽量详细记录这几天的摸索历程，以及对这些概念的理解和实践。
传送门：
kong网关中文文档
kong官网
kong官方文档
前言 近几天在学习api网关kong，发现中文网基本没人发表关于kong的consumer、plugin、route、service的进一步探索和使用相关文章，只是分开描述了单独的概念和做简单配置，因此为了补全这个缺失，我尽量详细记录这几天的摸索历程，以及对这些概念的理解和实践。
理论 Consumer The Consumer object represents a consumer - or a user - of an API. You can either rely on Kong as the primary datastore, or you can map the consumer list with your database to keep consistency between Kong and your existing primary datastore.
（官方原文解释中的消费者和数据库的映射这里暂时不涉及）
consumer直译消费者。它是个抽象概念，代表一类事物。例如你可以创建一组consumer代表api版本号v1、v2、v3， 也可以代表请求来源类型，来自客户端请求可标记为android/iOS， web前端请求标记为web frontend，IoT设备请求标记为IoT device。
Kong所在的架构好比一家公司，kong consumer 就代表公司员工种类，普通员工、主管、经理、老板等。当然，标记这些人员需要工牌，工牌上具有员工认证信息，无工牌社会人员无法进入。
请求未认证情况下不为consumer， 只会根据请求的customIP标记，因此请求被kong标记为consumer前需要进行认证。
kong提供了多种认证方式：BASIC AUTH、API KEYS、HMAC、OAUTH2、JWT
他们适合的使用场景都不同，按需设置，我这里需要用kong搭建分布式场景应用，因此选择JWT
（这里使用kong图形界面KONGA实践）
JWT验证需要key识别用户，secret为kong保存的私钥，algorithm为最终签名算法。</description>
    </item>
    
    <item>
      <title>pwn实践记录--rop入门</title>
      <link>https://shankisme.com/posts/%E5%85%A5%E9%97%A8pwn%E5%AE%9E%E8%B7%B5%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Sat, 07 Mar 2020 21:43:55 +0800</pubDate>
      
      <guid>https://shankisme.com/posts/%E5%85%A5%E9%97%A8pwn%E5%AE%9E%E8%B7%B5%E8%AE%B0%E5%BD%95/</guid>
      <description>前言 回过来记录入门历程主要是为了复习巩固pwn的分析思路。因为写的很详细，篇幅很长，未写完的会第二天写。全部内容包括：ret2shellcode、ret2libc(绕过NX)、ret2libc(绕过ASLR)、格式化字符串漏洞。若理解有错误，请在评论区指正。
本次回顾涉及到的elf文件以及exp都能在这里获取到。 环境准备：linux(32位程序运行环境)、IDA Pro、gdb插件、python+pwntools、不屈意志:) 知识回顾：操作系统预防二进制漏洞的保护机制、elf文件组成、栈机制、大小端。
0x00 return2shellcode 文件：level1 习惯性查看保护机制：
很好全关，接下来利用IDA Pro F5大法查看反汇编结果： 发现该二进制文件main函数入口直接调用vulnerable_function()函数，然后调用了write函数。这里提个醒，反汇编遇到write()、read()、puts()、gets()一定留个心眼，这些函数对任意变量的处理都可能造成栈溢出，不过本题输出的是字符串常量，忽略，直接查看vulnerable_function()。 看到该函数创建了个局部变量（数组指针），位置距离ebp-0x88的位置，也就是距离基指针136字节位置。read()函数读取了该函数的局部变量，上文提到read()函数不检查读取限制，并且局部变量存放在栈中，因此我们可以构造payload长度=136+4(存储ebp指针地址大小)+4(返回地址大小), 来改变函数返回地址。考虑到PIE已关，并且140字节的长度足够存储一个shellcode执行execve(&amp;quot;/bin/sh&amp;quot;)。因此我们从payload的开始位置存shellcode，剩下的用&amp;rsquo;A&amp;rsquo;补全，返回地址指向payload起始地址，也就是局部变量的起始地址。但是地址我们还不知道，因为它是在栈里面加载的。考虑到栈的动态变化，IDAPro的静态分析无法展示（它的动态分析比较麻烦），接下来用gdb配合peta插件进行动态分析： 在入口函数下断点： run/start 执行到main函数入口停下： 依次 next next 在汇编下一步执行vulnerable_function()函数的时候，step命令进入函数内部： 进入之后，我们就能看到该函数的栈情况了 接下来依次next 执行到read()函数的时候，象征性输入字符： 可以看到栈区0xffffd060地址上存放了该局部变量（上面的0xffffd060是文字常量区（常量池）范围内的地址，主要存储字符串常量），至此所有的分析工作就完成了。
接下来最最最关键的地方来了，很多初学者都会落进去的坑：其实gdb调试和实际执行程序的栈位置相比会有些偏移，为了提供buf更精确的位置，我们需要开启core dump功能来收集实际运行环境下的变量分布情况。 暂时开启core dump命令
ulimit -c unlimited 执行level1:
./level1 输入字符使栈溢出。 可以看到目录下多出来了个core文件。 接下来用gdb 配合core文件再次调试level1 然后输入 x $esp-144查看buf的位置, 这里的esp指的是实际环境下程序执行出错的时候的esp, 执行返回命令时，esp退回到main函数的栈顶，因此buf的位置 = esp指针存的位置 - payload的长度(144)。 得到buf实际地址：0xffffd0c0 接下来我们就能安心的写exp了。
from pwn import * p = process(&amp;#39;./level1&amp;#39;) ret = 0xffffd0c0 shellcode = &amp;#34;\x31\xc9\xf7\xe1\x51\x68\x2f\x2f\x73&amp;#34; shellcode += &amp;#34;\x68\x68\x2f\x62\x69\x6e\x89\xe3\xb0&amp;#34; shellcode += &amp;#34;\x0b\xcd\x80&amp;#34; payload = shellcode + &amp;#39;A&amp;#39; * (140 - len(shellcode)) + p32(ret) p.</description>
    </item>
    
    <item>
      <title>pwntools下踩的坑</title>
      <link>https://shankisme.com/posts/pwntools%E4%B8%8B%E8%B8%A9%E7%9A%84%E5%9D%91/</link>
      <pubDate>Tue, 25 Feb 2020 19:03:01 +0800</pubDate>
      
      <guid>https://shankisme.com/posts/pwntools%E4%B8%8B%E8%B8%A9%E7%9A%84%E5%9D%91/</guid>
      <description>纯pwn小白在疫情期间无聊，于是开始玩起了pwn。期间在i春秋,freebuf，知乎上随便看了几篇入门手册，难受的是技术活什么都看不懂。。距离上次接触汇编是大一下学期吧，当时计算机系统的实践课程要求做某常青藤的bomblab,当时跟着大佬的步骤勉强完成三关。探索的过程很累，尤其是在汇编知识还没消化完，就去做ret2somefunc的题，一个字：难，两个字：难顶。
废话不多说，下面记录配pwntools环境踩的坑。当然踩坑还是因为没有先好好读官方文档。
0x00 介绍 pwntools(v2.0)是编写漏洞利用脚本的python库，设计者将它分为两个模块：pwnlib与pwn。 pwnlib是个干净的模块，适合初学者快速入门。而pwn是打CTF专用的工具箱，是pwnlib的超集，功能更多，也更难入门。具体介绍请看pwntools文档。
0x01 pwntools不适配windows中的python。 我先尝试在windows环境下pip install pwn。很快就装好了，本以为直接运行python脚本就大功告成了，结果编译器告诉我：
行吧，缺东西，咱用pip补上，但是发现_curses仅支持linux，巧的是在win平台上有对应轮子。然后还是会有问题，就开始无限打补丁。。当然最后脑子没抽到底，换到了linux内,这里推荐ubuntu linux 64。
0x02 要想方便流畅写exp，最好装在python2内。 为什么？因为从python3开始，str和bytes的边界不再模糊。python2中 str+bytes能合并成bytes，默认将str以ascii编码解码，而python3中，除非加法重定向，否则无法合并成统一格式。所以在python3中要想合并str和bytes。只能str.encode(&#39;ascii&#39;)+bytes或者str.encode+bytes.decode(&#39;ascii&#39;)
0x03 pwntools不适合装在32位系统中 该坑是我在ubuntu 32安装pwntools遇到的，执行exp会有警告，pwntools仍然会起作用，但是具体会产生什么影响我也不清楚，因为当时还在写最简单的exp, 栈溢出攻击，ret2shellcode攻击。
另外，pwntools真的是非常好的工具，接口很齐全，谁用谁知道。
完。</description>
    </item>
    
    <item>
      <title>ctf水题---传感器</title>
      <link>https://shankisme.com/posts/%E4%BC%A0%E6%84%9F%E5%99%A8/</link>
      <pubDate>Fri, 21 Feb 2020 01:07:00 +0800</pubDate>
      
      <guid>https://shankisme.com/posts/%E4%BC%A0%E6%84%9F%E5%99%A8/</guid>
      <description>本着入门的想法，在writeup的帮助下，试做人生中第一道CTF赛题, 本文目的是还原脱离wp的写题思路。
题目出自 i春秋CTF大本营: 2017届全国大学生信息安全竞赛
已知 A传感器的ID和它的输出， 以及B的输出。 求另一个传感器B的ID。
大致思路是从输出中寻找输出和ID的联系，而A的ID和输出就是线索。
发现输出是16进制，遇到进制问题首先做的肯定是比对进制转换后的数字。
先用在线工具转换一下A的输出 发现最有规律的是2进制和8进制数据 但是考虑到8进制不常用，并且它的规律集中在52上，没法利用 所以接下来看2进制： 2进制数据除了前5个1，后面的数据都以二进制对01，10的形式在做排列组合 我们需要的是有规律的数， 所以可以舍弃掉输出中的前两位(3E , 5个1包含在其中) 继续观察余下的二进制数 发现很像数字逻辑中的电平跳变，0代表低位，1代表高位 该二进制数据可能是在传输数据。但是没有连续的0和1，因此该数据很有可能经过编码 查找各编码形式后发现只有曼切斯特编码和差分曼切斯特编码符合这个规律
曼切斯特编码： data用跳变表示，0和1对应01和10 至于谁对应谁有两种标准： 差分曼切斯特编码： 数字信号对应电平跳变，存在初始电平跳变cc=01, 当前的信号为0意味着当前跳变和上一个跳变相同，为1意味着当前跳变和前一个跳变不同。 知识回顾的差不多了，回到题目，开始撸代码 由于涉及到各种进制转换和划分，c++和java过于反人类，啥都要自己写，不如用python,python很多内嵌方法就能进行进制转换和划分了。 思路很简单 直接贴代码：
import re def bintohex(s1): s = re.findall(&amp;#39;.{4}&amp;#39;, s1) s2 = &amp;#39;&amp;#39; for i in s: s2 += str(hex(int(i, 2))).replace(&amp;#39;0x&amp;#39;,&amp;#39;&amp;#39;) return s2 def diffmqst(s1): #差分曼切斯特 pre = &amp;#39;01&amp;#39; rst = &amp;#39;&amp;#39; s = re.findall(&amp;#39;.{2}&amp;#39;,s1) for i in s: if i==pre: rst += &amp;#39;0&amp;#39; else : rst+=&amp;#39;1&amp;#39; pre = i return rst if __name__ == &amp;#39;__main__&amp;#39;: hex1 = &amp;#39;AAAAA56A69AA55A95995A569AA95565556&amp;#39; hex2 = &amp;#39;0x8893CA58&amp;#39; bin1 = bin(int(hex1, 16)).</description>
    </item>
    
  </channel>
</rss>
